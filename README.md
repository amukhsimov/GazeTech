
<div align="center">

<h2>Investigation of Architectures and Receptive Fields for Appearance-based Gaze Estimation</h2>

<div>
    Yunhan Wang</a><sup>1</sup>&emsp;
    Xiangwei Shi</a><sup>1</sup>&emsp;
    Shalini De  Mello</a><sup>2</sup>&emsp;
    Hyung Jin Chang</a><sup>3</sup>&emsp;
    Xucong Zhang</a><sup>1</sup>&emsp;
</div>

<div>
    <sup>1</sup>Computer Vision Lab, Delft University of Technology&emsp;
    <sup>2</sup>NVIDIA&emsp; <br>
    <sup>3</sup>School of Computer Science, University of Birmingham
</div>

</div>

<br/>

# Description
This repository contains frameworks for pre-processing, training and evaluating full face or multi-region (face, left and right eyes) gaze estimation models on the following three datasets: ETH-XGaze, MPII-Gaze, and Gaze360. These frameworks allow to flexibly load single face input or multi-region input and serve to reproduce our results and benchmark new models.

# Links

# Setup

# Bibtex

# License
